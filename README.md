<p align="center">

  <h2 align="center"> DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models </h2>
  <p align="center">
        <a href="https://arxiv.org/abs/2508.08961">
        <img src='https://img.shields.io/badge/arXiv-red' alt='Paper Arxiv'></a> &nbsp; &nbsp;  &nbsp; 
        <a href='https://lavendery.github.io/Unified-Understanding-and-Generalization-Demo/'>
        <img src='https://img.shields.io/badge/Project_Page-green' alt='Project Page'></a> &nbsp;&nbsp; &nbsp; 
  </p>
    </p>

This repo contains our official implementation of <strong> DualSpeechLM </strong>. For the generated audio, Please refer to [[Demo]](https://lavendery.github.io/Unified-Understanding-and-Generalization-Demo/). You can find our paper from [[Paper]](https://arxiv.org/abs/2508.08961).

## ðŸ“£ News & TODOs
- [x] **[2025.08.12]** Release paper and project page.
- [ ] Release USTokenizer code (coming soon).
- [ ] Release DualSpeechLM code (coming soon).
